import numpy as np
from numpy import dot
from scipy.linalg import cholesky, inv, solve, cho_solve
from matplotlib import pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C
import scipy
import operator

class LocalModel(object):
    def __init__(self, opt,D):
        self.D=D
        self.opt = opt
        self.set_initial_state()
        self.trained=False
        self.unique=None
        
    def set_initial_state(self):
        self.center = np.array(self.D) #figure out why this is the initial state... might be wrong
        self.lm=None #added, to save the local gp trained maybe.. who knows
        self.X=None
        self.Y=None
        self.num_data = 0
        self.eta = self.opt.init_eta
        self.kernel=self.opt.kern
        self.gp= GaussianProcessRegressor(kernel=self.kernel,alpha=1e-10,n_restarts_optimizer=self.opt.n_restarts_optimizer)
        return
    
    def init_lm(self, X=None, y=None, noise=None):
        if noise==None:
            noise=1e-10
        if X.ndim==1:
            self.center = X
        else:
            self.center = np.mean(X,axis=0)
        if (X is not None) and (y is not None):
        	gp=GaussianProcessRegressor(kernel=self.kernel,alpha=noise,n_restarts_optimizer=self.opt.n_restarts_optimizer)
        	self.X=X
        	self.Y=y
        	dist = X - self.center
        	self.gp=gp.fit(dist, y)
        	self.kernel=gp.kernel_
        	self.trained=True
        	self.overlap=np.zeros(y.shape)
        return
    
    
    def get_ww(self, X):
        return self.kernel(self.center,X)
        
    def get_wwP(self, X):
        w=np.zeros(X.shape[0])
        if self.X.shape[0]==1:
              w=np.zeros(X.shape[0])
        else:
            w=self.kernel(self.center,X)
        return w
        
    def get_wk2(self, X):
        return self.kernel.k2(self.center,X)
    def get_wpk2(self, X):
    	w=[]
    	for i in X:
    		dist=scipy.spatial.distance.cdist(self.X,i.reshape(1,1))
    		index, min_act = min(enumerate(dist), key=operator.itemgetter(1))
    		ww=self.kernel.k2(self.X[index],i.reshape(1,1))
    		w.append(ww)
    	return np.asarray(w).reshape(1,len(X))
        
    def get_wpred(self, X):
    	w=[]
    	for i in X:
    		dist=scipy.spatial.distance.cdist(self.X,i.reshape(1,1))
    		index, min_act = min(enumerate(dist), key=operator.itemgetter(1))
    		ww=self.kernel(self.X[index],i.reshape(1,1))
    		w.append(ww)
    	return np.asarray(w).reshape(1,len(X))
    def predict_2(self, X):
    	dist=[]
    	for i in X:
    		d=scipy.spatial.distance.cdist(self.X,i.reshape(1,1))
    		index, min_act = min(enumerate(d), key=operator.itemgetter(1))
    		dist.append((self.X[index]-i))
    	dist=np.asarray(dist)
    	y_pred, sigma = self.gp.predict(dist, return_std=True)
    	return y_pred, sigma
    
    def predict_(self, X):
    	dist=X-self.center
    	y_pred, sigma = self.gp.predict(dist, return_std=True)
    	return y_pred, sigma
    
    def update_(self,x_n,y_new,noise=None):
        if noise is None:
            noise=1e-10
        if self.trained is True:
            
            dim=len(self.gp.X_train_)
            
            self.X=np.concatenate((self.X,x_n),axis=0) #save all of the data used for training
            self.Y=np.concatenate((self.Y,y_new),axis=0)
            self.center = np.mean(self.X,axis=0)
            x_new=x_n-self.center
            k_new=self.kernel(x_new,x_new)+noise
            kk_new=self.kernel(self.gp.X_train_,x_new)
            self.gp.X_train_=self.X-self.center
            self.gp.y_train_=self.Y
            
            l=solve(self.gp.L_,kk_new) 
            l_star=np.sqrt(abs(k_new-dot(l.T,l)))
            a=np.concatenate((self.gp.L_,np.zeros(dim).reshape(dim,1)),axis=1) 
            b=np.concatenate((l.T,l_star.reshape(1,1)),axis=1)
            L_new= np.concatenate((a,b),axis=0)
            alpha_new=cho_solve((L_new, True), self.gp.y_train_)
 
            self.gp.L_=L_new        #update the relavant  variables in the GP
            self.gp.alpha_=alpha_new
            self.gp._K_inv=None
        else: 
            raise ValueError('LM not trained!')
    
    
       
